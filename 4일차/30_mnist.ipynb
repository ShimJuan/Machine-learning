{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-71e12f4bac70>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\anaconda\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\anaconda\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\anaconda\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\anaconda\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\anaconda\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x00000249299AF148>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x0000024929A9C348>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x0000024929C7BC88>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = mnist.train.images\n",
    "x_test = mnist.test.images\n",
    "y_train = mnist.train.labels\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape # 로우 하나가 이미지 하나를 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape # one hot encoding으로 제공된다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중분류 : softmax 사용\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.constant(y_train, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.variable_scope.get_variable(name, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, collections=None, caching_device=None, partitioner=None, validate_shape=True, use_resource=None, custom_getter=None, constraint=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 딥러닝을 안할시에는 밑의 코드 사용\n",
    "# w = tf.Variable(tf.random_uniform([784,10]))\n",
    "# b = tf.Variable(tf.random_uniform([10]))\n",
    "\n",
    "# w1 = tf.Variable(tf.random_uniform([784,10]))\n",
    "# b1 = tf.Variable(tf.random_uniform([10]))\n",
    "# w2 = tf.Variable(tf.random_uniform([100,10]))\n",
    "# b2 = tf.Variable(tf.random_uniform([10]))\n",
    "# 784,10은 맞추고 나머지는 하이퍼파라미터로 설정\n",
    "w1 = tf.get_variable( 'w1',[784,100], initializer=tf.contrib.layers.xavier_initializer()) \n",
    "b1 = tf.get_variable( 'b1',[100], initializer=tf.contrib.layers.xavier_initializer())\n",
    "w2 = tf.get_variable( 'w2',[100,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.get_variable( 'b2',[10], initializer=tf.contrib.layers.xavier_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = tf.matmul(x,w1)+b1\n",
    "lay1 = tf.nn.relu(z1) # 확률값 추출 # 학습이 잘 안된다면 relu를 사용할 필요가 있다. 하지만 최종은 softmax를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "z2 = tf.matmul(lay1,w2)+b2\n",
    "hx = tf.nn.softmax(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-51b38eb5a0ce>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost_i=tf.nn.softmax_cross_entropy_with_logits(logits=z2,labels=y)\n",
    "cost = tf.reduce_mean( cost_i )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.1) #learning rate\n",
    "train = optimizer.minimize(cost)\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.3071933\n",
      "1 2.214053\n",
      "2 2.1305559\n",
      "3 2.0527377\n",
      "4 1.9783332\n",
      "5 1.9063827\n",
      "6 1.8366065\n",
      "7 1.7690302\n",
      "8 1.7037911\n",
      "9 1.6410356\n",
      "10 1.5809239\n",
      "11 1.5235605\n",
      "12 1.4689653\n",
      "13 1.41714\n",
      "14 1.3680656\n",
      "15 1.3216952\n",
      "16 1.2779975\n",
      "17 1.2368724\n",
      "18 1.1981844\n",
      "19 1.1618155\n",
      "20 1.1276352\n",
      "21 1.0955149\n",
      "22 1.0653498\n",
      "23 1.0370017\n",
      "24 1.010359\n",
      "25 0.9853129\n",
      "26 0.96175414\n",
      "27 0.93959105\n",
      "28 0.9187144\n",
      "29 0.8990213\n",
      "30 0.8804334\n",
      "31 0.862876\n",
      "32 0.84626997\n",
      "33 0.83054817\n",
      "34 0.81564647\n",
      "35 0.80150944\n",
      "36 0.7880818\n",
      "37 0.7753189\n",
      "38 0.763173\n",
      "39 0.7516022\n",
      "40 0.74056584\n",
      "41 0.73002434\n",
      "42 0.7199499\n",
      "43 0.7103132\n",
      "44 0.70108646\n",
      "45 0.69224244\n",
      "46 0.6837624\n",
      "47 0.67562383\n",
      "48 0.6678065\n",
      "49 0.6602911\n",
      "50 0.65305924\n",
      "51 0.64609605\n",
      "52 0.63938653\n",
      "53 0.6329188\n",
      "54 0.62667984\n",
      "55 0.6206578\n",
      "56 0.61484134\n",
      "57 0.60921735\n",
      "58 0.60377836\n",
      "59 0.5985159\n",
      "60 0.59342045\n",
      "61 0.58848435\n",
      "62 0.58369935\n",
      "63 0.5790599\n",
      "64 0.57455987\n",
      "65 0.5701938\n",
      "66 0.5659554\n",
      "67 0.56183857\n",
      "68 0.55783737\n",
      "69 0.5539479\n",
      "70 0.55016583\n",
      "71 0.5464864\n",
      "72 0.5429051\n",
      "73 0.5394178\n",
      "74 0.5360209\n",
      "75 0.53270996\n",
      "76 0.529482\n",
      "77 0.5263341\n",
      "78 0.5232628\n",
      "79 0.5202656\n",
      "80 0.5173396\n",
      "81 0.51448274\n",
      "82 0.51169235\n",
      "83 0.50896615\n",
      "84 0.50630224\n",
      "85 0.5036978\n",
      "86 0.5011511\n",
      "87 0.49866024\n",
      "88 0.49622315\n",
      "89 0.49383825\n",
      "90 0.49150363\n",
      "91 0.48921746\n",
      "92 0.48697826\n",
      "93 0.48478472\n",
      "94 0.48263538\n",
      "95 0.48052877\n",
      "96 0.47846392\n",
      "97 0.4764397\n",
      "98 0.47445425\n",
      "99 0.4725064\n",
      "100 0.4705951\n",
      "101 0.4687193\n",
      "102 0.4668779\n",
      "103 0.46507004\n",
      "104 0.46329457\n",
      "105 0.46155074\n",
      "106 0.4598378\n",
      "107 0.4581549\n",
      "108 0.4565011\n",
      "109 0.45487553\n",
      "110 0.45327795\n",
      "111 0.45170754\n",
      "112 0.45016354\n",
      "113 0.4486448\n",
      "114 0.44715038\n",
      "115 0.4456799\n",
      "116 0.4442323\n",
      "117 0.44280738\n",
      "118 0.44140497\n",
      "119 0.44002435\n",
      "120 0.4386649\n",
      "121 0.43732628\n",
      "122 0.43600765\n",
      "123 0.43470892\n",
      "124 0.43342957\n",
      "125 0.4321691\n",
      "126 0.43092734\n",
      "127 0.42970327\n",
      "128 0.4284968\n",
      "129 0.42730746\n",
      "130 0.42613474\n",
      "131 0.42497835\n",
      "132 0.4238378\n",
      "133 0.42271292\n",
      "134 0.4216035\n",
      "135 0.42050877\n",
      "136 0.4194284\n",
      "137 0.41836238\n",
      "138 0.41731042\n",
      "139 0.41627216\n",
      "140 0.4152473\n",
      "141 0.41423538\n",
      "142 0.41323605\n",
      "143 0.4122492\n",
      "144 0.41127464\n",
      "145 0.4103119\n",
      "146 0.40936077\n",
      "147 0.40842128\n",
      "148 0.40749308\n",
      "149 0.40657586\n",
      "150 0.40566945\n",
      "151 0.4047736\n",
      "152 0.40388796\n",
      "153 0.40301272\n",
      "154 0.40214723\n",
      "155 0.40129137\n",
      "156 0.40044525\n",
      "157 0.39960852\n",
      "158 0.39878112\n",
      "159 0.39796278\n",
      "160 0.39715335\n",
      "161 0.39635265\n",
      "162 0.3955606\n",
      "163 0.39477706\n",
      "164 0.3940018\n",
      "165 0.39323458\n",
      "166 0.39247537\n",
      "167 0.39172366\n",
      "168 0.39097944\n",
      "169 0.39024264\n",
      "170 0.38951328\n",
      "171 0.388791\n",
      "172 0.38807574\n",
      "173 0.38736755\n",
      "174 0.38666606\n",
      "175 0.38597125\n",
      "176 0.38528308\n",
      "177 0.38460135\n",
      "178 0.38392603\n",
      "179 0.3832571\n",
      "180 0.38259447\n",
      "181 0.38193777\n",
      "182 0.381287\n",
      "183 0.38064215\n",
      "184 0.38000298\n",
      "185 0.37936947\n",
      "186 0.37874147\n",
      "187 0.37811896\n",
      "188 0.37750196\n",
      "189 0.3768902\n",
      "190 0.37628362\n",
      "191 0.37568203\n",
      "192 0.3750856\n",
      "193 0.37449405\n",
      "194 0.37390724\n",
      "195 0.37332544\n",
      "196 0.37274843\n",
      "197 0.37217605\n",
      "198 0.37160802\n",
      "199 0.3710446\n",
      "200 0.37048566\n",
      "201 0.36993104\n",
      "202 0.36938092\n",
      "203 0.368835\n",
      "204 0.36829332\n",
      "205 0.36775574\n",
      "206 0.3672223\n",
      "207 0.36669296\n",
      "208 0.36616755\n",
      "209 0.36564595\n",
      "210 0.36512846\n",
      "211 0.36461478\n",
      "212 0.36410475\n",
      "213 0.3635984\n",
      "214 0.36309567\n",
      "215 0.3625965\n",
      "216 0.36210093\n",
      "217 0.361609\n",
      "218 0.36112052\n",
      "219 0.3606354\n",
      "220 0.3601537\n",
      "221 0.35967526\n",
      "222 0.35920012\n",
      "223 0.35872802\n",
      "224 0.35825908\n",
      "225 0.3577934\n",
      "226 0.35733062\n",
      "227 0.3568708\n",
      "228 0.35641393\n",
      "229 0.35595983\n",
      "230 0.3555086\n",
      "231 0.35506025\n",
      "232 0.3546147\n",
      "233 0.3541718\n",
      "234 0.35373145\n",
      "235 0.3532938\n",
      "236 0.35285905\n",
      "237 0.35242704\n",
      "238 0.35199788\n",
      "239 0.35157144\n",
      "240 0.3511475\n",
      "241 0.3507261\n",
      "242 0.3503072\n",
      "243 0.34989077\n",
      "244 0.3494767\n",
      "245 0.34906512\n",
      "246 0.34865582\n",
      "247 0.3482489\n",
      "248 0.3478441\n",
      "249 0.3474417\n",
      "250 0.3470416\n",
      "251 0.34664372\n",
      "252 0.3462481\n",
      "253 0.34585476\n",
      "254 0.34546378\n",
      "255 0.34507495\n",
      "256 0.3446884\n",
      "257 0.3443039\n",
      "258 0.34392133\n",
      "259 0.34354097\n",
      "260 0.3431625\n",
      "261 0.34278598\n",
      "262 0.34241143\n",
      "263 0.34203893\n",
      "264 0.34166834\n",
      "265 0.34129965\n",
      "266 0.34093297\n",
      "267 0.34056816\n",
      "268 0.34020498\n",
      "269 0.33984342\n",
      "270 0.33948368\n",
      "271 0.33912566\n",
      "272 0.33876944\n",
      "273 0.33841485\n",
      "274 0.33806208\n",
      "275 0.33771116\n",
      "276 0.33736193\n",
      "277 0.33701438\n",
      "278 0.33666846\n",
      "279 0.3363244\n",
      "280 0.33598182\n",
      "281 0.33564097\n",
      "282 0.3353017\n",
      "283 0.3349641\n",
      "284 0.33462813\n",
      "285 0.33429375\n",
      "286 0.3339608\n",
      "287 0.33362934\n",
      "288 0.3332994\n",
      "289 0.33297104\n",
      "290 0.3326441\n",
      "291 0.3323189\n",
      "292 0.33199498\n",
      "293 0.33167276\n",
      "294 0.3313519\n",
      "295 0.33103245\n",
      "296 0.3307143\n",
      "297 0.33039737\n",
      "298 0.33008176\n",
      "299 0.32976755\n",
      "300 0.32945475\n",
      "301 0.3291432\n",
      "302 0.3288329\n",
      "303 0.32852387\n",
      "304 0.328216\n",
      "305 0.32790935\n",
      "306 0.3276037\n",
      "307 0.3272992\n",
      "308 0.32699624\n",
      "309 0.32669467\n",
      "310 0.32639426\n",
      "311 0.32609516\n",
      "312 0.3257974\n",
      "313 0.32550097\n",
      "314 0.32520565\n",
      "315 0.3249115\n",
      "316 0.32461846\n",
      "317 0.3243267\n",
      "318 0.3240363\n",
      "319 0.3237468\n",
      "320 0.32345852\n",
      "321 0.32317135\n",
      "322 0.32288516\n",
      "323 0.32260007\n",
      "324 0.32231617\n",
      "325 0.32203346\n",
      "326 0.3217517\n",
      "327 0.3214711\n",
      "328 0.32119155\n",
      "329 0.32091305\n",
      "330 0.3206355\n",
      "331 0.32035908\n",
      "332 0.32008368\n",
      "333 0.31980923\n",
      "334 0.3195358\n",
      "335 0.31926322\n",
      "336 0.31899154\n",
      "337 0.31872097\n",
      "338 0.3184512\n",
      "339 0.31818235\n",
      "340 0.31791434\n",
      "341 0.3176473\n",
      "342 0.31738117\n",
      "343 0.31711605\n",
      "344 0.31685176\n",
      "345 0.31658846\n",
      "346 0.31632596\n",
      "347 0.3160642\n",
      "348 0.31580347\n",
      "349 0.31554368\n",
      "350 0.31528488\n",
      "351 0.31502673\n",
      "352 0.3147694\n",
      "353 0.314513\n",
      "354 0.31425762\n",
      "355 0.314003\n",
      "356 0.31374922\n",
      "357 0.3134962\n",
      "358 0.313244\n",
      "359 0.3129927\n",
      "360 0.31274202\n",
      "361 0.31249216\n",
      "362 0.31224307\n",
      "363 0.31199488\n",
      "364 0.31174755\n",
      "365 0.311501\n",
      "366 0.31125534\n",
      "367 0.3110103\n",
      "368 0.31076595\n",
      "369 0.31052253\n",
      "370 0.3102798\n",
      "371 0.31003797\n",
      "372 0.30979702\n",
      "373 0.3095569\n",
      "374 0.3093175\n",
      "375 0.3090789\n",
      "376 0.30884108\n",
      "377 0.30860397\n",
      "378 0.30836755\n",
      "379 0.3081319\n",
      "380 0.30789673\n",
      "381 0.30766228\n",
      "382 0.30742848\n",
      "383 0.3071953\n",
      "384 0.306963\n",
      "385 0.30673113\n",
      "386 0.3065\n",
      "387 0.30626953\n",
      "388 0.30603984\n",
      "389 0.30581084\n",
      "390 0.30558237\n",
      "391 0.30535448\n",
      "392 0.30512717\n",
      "393 0.30490047\n",
      "394 0.3046744\n",
      "395 0.304449\n",
      "396 0.30422428\n",
      "397 0.304\n",
      "398 0.3037762\n",
      "399 0.30355301\n",
      "400 0.30333042\n",
      "401 0.3031083\n",
      "402 0.3028867\n",
      "403 0.30266562\n",
      "404 0.30244532\n",
      "405 0.3022255\n",
      "406 0.30200633\n",
      "407 0.30178764\n",
      "408 0.3015696\n",
      "409 0.30135208\n",
      "410 0.3011351\n",
      "411 0.30091876\n",
      "412 0.30070284\n",
      "413 0.3004874\n",
      "414 0.30027243\n",
      "415 0.30005804\n",
      "416 0.29984412\n",
      "417 0.29963088\n",
      "418 0.29941812\n",
      "419 0.2992059\n",
      "420 0.2989941\n",
      "421 0.29878289\n",
      "422 0.29857215\n",
      "423 0.29836202\n",
      "424 0.29815236\n",
      "425 0.29794312\n",
      "426 0.29773444\n",
      "427 0.2975261\n",
      "428 0.29731825\n",
      "429 0.29711092\n",
      "430 0.29690406\n",
      "431 0.29669777\n",
      "432 0.2964919\n",
      "433 0.2962865\n",
      "434 0.2960816\n",
      "435 0.29587722\n",
      "436 0.29567316\n",
      "437 0.2954698\n",
      "438 0.29526678\n",
      "439 0.29506424\n",
      "440 0.2948623\n",
      "441 0.2946606\n",
      "442 0.2944593\n",
      "443 0.29425848\n",
      "444 0.29405802\n",
      "445 0.29385793\n",
      "446 0.2936583\n",
      "447 0.29345894\n",
      "448 0.29326004\n",
      "449 0.29306155\n",
      "450 0.2928636\n",
      "451 0.29266608\n",
      "452 0.29246888\n",
      "453 0.29227212\n",
      "454 0.2920758\n",
      "455 0.29188016\n",
      "456 0.29168496\n",
      "457 0.29149023\n",
      "458 0.29129586\n",
      "459 0.291102\n",
      "460 0.2909086\n",
      "461 0.29071563\n",
      "462 0.29052308\n",
      "463 0.29033113\n",
      "464 0.29013956\n",
      "465 0.28994828\n",
      "466 0.28975743\n",
      "467 0.28956696\n",
      "468 0.28937685\n",
      "469 0.28918704\n",
      "470 0.28899774\n",
      "471 0.2888087\n",
      "472 0.28862026\n",
      "473 0.28843218\n",
      "474 0.28824455\n",
      "475 0.28805724\n",
      "476 0.2878702\n",
      "477 0.28768367\n",
      "478 0.2874976\n",
      "479 0.28731197\n",
      "480 0.28712678\n",
      "481 0.28694198\n",
      "482 0.28675756\n",
      "483 0.28657344\n",
      "484 0.28638956\n",
      "485 0.286206\n",
      "486 0.286023\n",
      "487 0.28584033\n",
      "488 0.28565806\n",
      "489 0.28547615\n",
      "490 0.28529465\n",
      "491 0.28511354\n",
      "492 0.28493258\n",
      "493 0.28475195\n",
      "494 0.2845717\n",
      "495 0.28439173\n",
      "496 0.2842121\n",
      "497 0.28403282\n",
      "498 0.2838539\n",
      "499 0.28367534\n",
      "500 0.28349733\n",
      "501 0.28331968\n",
      "502 0.2831424\n",
      "503 0.28296554\n",
      "504 0.28278905\n",
      "505 0.28261286\n",
      "506 0.28243703\n",
      "507 0.28226155\n",
      "508 0.28208634\n",
      "509 0.28191167\n",
      "510 0.2817373\n",
      "511 0.28156313\n",
      "512 0.28138927\n",
      "513 0.28121573\n",
      "514 0.28104264\n",
      "515 0.2808699\n",
      "516 0.28069755\n",
      "517 0.28052562\n",
      "518 0.28035402\n",
      "519 0.2801828\n",
      "520 0.2800119\n",
      "521 0.2798413\n",
      "522 0.27967107\n",
      "523 0.27950105\n",
      "524 0.27933133\n",
      "525 0.2791619\n",
      "526 0.2789927\n",
      "527 0.27882385\n",
      "528 0.27865526\n",
      "529 0.27848703\n",
      "530 0.27831918\n",
      "531 0.27815166\n",
      "532 0.27798456\n",
      "533 0.27781773\n",
      "534 0.27765095\n",
      "535 0.27748445\n",
      "536 0.27731827\n",
      "537 0.27715233\n",
      "538 0.27698684\n",
      "539 0.27682155\n",
      "540 0.27665654\n",
      "541 0.27649188\n",
      "542 0.27632746\n",
      "543 0.27616343\n",
      "544 0.2759997\n",
      "545 0.27583632\n",
      "546 0.27567312\n",
      "547 0.2755102\n",
      "548 0.27534756\n",
      "549 0.27518517\n",
      "550 0.27502304\n",
      "551 0.27486134\n",
      "552 0.27469987\n",
      "553 0.27453876\n",
      "554 0.27437794\n",
      "555 0.27421737\n",
      "556 0.274057\n",
      "557 0.273897\n",
      "558 0.27373728\n",
      "559 0.27357778\n",
      "560 0.27341864\n",
      "561 0.27325988\n",
      "562 0.27310127\n",
      "563 0.272943\n",
      "564 0.272785\n",
      "565 0.27262732\n",
      "566 0.27246976\n",
      "567 0.27231246\n",
      "568 0.27215546\n",
      "569 0.27199864\n",
      "570 0.27184212\n",
      "571 0.2716859\n",
      "572 0.27153\n",
      "573 0.2713743\n",
      "574 0.27121875\n",
      "575 0.27106348\n",
      "576 0.27090862\n",
      "577 0.270754\n",
      "578 0.2705996\n",
      "579 0.27044547\n",
      "580 0.27029163\n",
      "581 0.270138\n",
      "582 0.26998463\n",
      "583 0.26983145\n",
      "584 0.26967856\n",
      "585 0.2695259\n",
      "586 0.26937345\n",
      "587 0.26922116\n",
      "588 0.26906914\n",
      "589 0.26891738\n",
      "590 0.2687659\n",
      "591 0.2686147\n",
      "592 0.26846367\n",
      "593 0.268313\n",
      "594 0.26816255\n",
      "595 0.26801252\n",
      "596 0.2678628\n",
      "597 0.26771328\n",
      "598 0.2675641\n",
      "599 0.26741502\n",
      "600 0.2672662\n",
      "601 0.2671176\n",
      "602 0.2669692\n",
      "603 0.266821\n",
      "604 0.26667306\n",
      "605 0.26652524\n",
      "606 0.2663777\n",
      "607 0.26623037\n",
      "608 0.26608333\n",
      "609 0.26593646\n",
      "610 0.26578984\n",
      "611 0.26564336\n",
      "612 0.26549724\n",
      "613 0.26535133\n",
      "614 0.26520565\n",
      "615 0.2650602\n",
      "616 0.26491496\n",
      "617 0.26476988\n",
      "618 0.264625\n",
      "619 0.26448026\n",
      "620 0.26433584\n",
      "621 0.26419154\n",
      "622 0.26404747\n",
      "623 0.26390365\n",
      "624 0.2637601\n",
      "625 0.26361677\n",
      "626 0.26347372\n",
      "627 0.26333103\n",
      "628 0.26318854\n",
      "629 0.26304638\n",
      "630 0.26290423\n",
      "631 0.2627623\n",
      "632 0.26262066\n",
      "633 0.2624792\n",
      "634 0.26233792\n",
      "635 0.2621968\n",
      "636 0.26205593\n",
      "637 0.26191518\n",
      "638 0.26177457\n",
      "639 0.26163417\n",
      "640 0.26149398\n",
      "641 0.261354\n",
      "642 0.26121408\n",
      "643 0.26107433\n",
      "644 0.26093474\n",
      "645 0.26079533\n",
      "646 0.26065615\n",
      "647 0.26051718\n",
      "648 0.26037842\n",
      "649 0.26023987\n",
      "650 0.26010147\n",
      "651 0.2599633\n",
      "652 0.2598254\n",
      "653 0.25968772\n",
      "654 0.25955024\n",
      "655 0.25941294\n",
      "656 0.25927588\n",
      "657 0.25913897\n",
      "658 0.25900227\n",
      "659 0.25886574\n",
      "660 0.25872937\n",
      "661 0.25859317\n",
      "662 0.2584572\n",
      "663 0.2583215\n",
      "664 0.25818598\n",
      "665 0.25805065\n",
      "666 0.25791553\n",
      "667 0.2577805\n",
      "668 0.25764582\n",
      "669 0.25751123\n",
      "670 0.25737688\n",
      "671 0.2572427\n",
      "672 0.25710884\n",
      "673 0.2569752\n",
      "674 0.25684166\n",
      "675 0.25670832\n",
      "676 0.25657514\n",
      "677 0.25644216\n",
      "678 0.25630933\n",
      "679 0.25617677\n",
      "680 0.25604433\n",
      "681 0.2559121\n",
      "682 0.25577998\n",
      "683 0.25564808\n",
      "684 0.25551638\n",
      "685 0.25538486\n",
      "686 0.25525355\n",
      "687 0.25512245\n",
      "688 0.25499147\n",
      "689 0.2548606\n",
      "690 0.25472987\n",
      "691 0.25459936\n",
      "692 0.25446898\n",
      "693 0.2543388\n",
      "694 0.25420874\n",
      "695 0.25407895\n",
      "696 0.25394925\n",
      "697 0.2538198\n",
      "698 0.2536905\n",
      "699 0.25356138\n",
      "700 0.2534324\n",
      "701 0.25330362\n",
      "702 0.2531749\n",
      "703 0.25304633\n",
      "704 0.25291795\n",
      "705 0.25278974\n",
      "706 0.25266162\n",
      "707 0.25253367\n",
      "708 0.25240585\n",
      "709 0.25227824\n",
      "710 0.25215077\n",
      "711 0.25202355\n",
      "712 0.25189653\n",
      "713 0.25176972\n",
      "714 0.251643\n",
      "715 0.25151634\n",
      "716 0.2513899\n",
      "717 0.25126356\n",
      "718 0.25113738\n",
      "719 0.25101134\n",
      "720 0.25088558\n",
      "721 0.25075987\n",
      "722 0.2506343\n",
      "723 0.2505089\n",
      "724 0.25038362\n",
      "725 0.2502585\n",
      "726 0.25013354\n",
      "727 0.25000867\n",
      "728 0.24988398\n",
      "729 0.24975944\n",
      "730 0.24963501\n",
      "731 0.24951072\n",
      "732 0.2493865\n",
      "733 0.24926245\n",
      "734 0.24913856\n",
      "735 0.24901481\n",
      "736 0.24889112\n",
      "737 0.24876761\n",
      "738 0.24864417\n",
      "739 0.24852096\n",
      "740 0.24839792\n",
      "741 0.24827504\n",
      "742 0.24815229\n",
      "743 0.24802966\n",
      "744 0.24790718\n",
      "745 0.24778481\n",
      "746 0.2476626\n",
      "747 0.2475406\n",
      "748 0.24741863\n",
      "749 0.24729687\n",
      "750 0.24717529\n",
      "751 0.24705373\n",
      "752 0.24693236\n",
      "753 0.24681108\n",
      "754 0.24668992\n",
      "755 0.2465688\n",
      "756 0.24644785\n",
      "757 0.24632698\n",
      "758 0.2462063\n",
      "759 0.24608569\n",
      "760 0.2459653\n",
      "761 0.2458451\n",
      "762 0.24572507\n",
      "763 0.24560516\n",
      "764 0.24548541\n",
      "765 0.24536574\n",
      "766 0.24524617\n",
      "767 0.24512674\n",
      "768 0.2450075\n",
      "769 0.2448884\n",
      "770 0.24476942\n",
      "771 0.24465063\n",
      "772 0.24453193\n",
      "773 0.24441329\n",
      "774 0.24429478\n",
      "775 0.24417637\n",
      "776 0.24405813\n",
      "777 0.24393998\n",
      "778 0.243822\n",
      "779 0.24370408\n",
      "780 0.24358626\n",
      "781 0.24346861\n",
      "782 0.2433511\n",
      "783 0.24323373\n",
      "784 0.24311645\n",
      "785 0.24299926\n",
      "786 0.24288216\n",
      "787 0.24276516\n",
      "788 0.24264826\n",
      "789 0.24253163\n",
      "790 0.24241504\n",
      "791 0.2422986\n",
      "792 0.24218218\n",
      "793 0.24206586\n",
      "794 0.24194965\n",
      "795 0.2418336\n",
      "796 0.24171773\n",
      "797 0.2416019\n",
      "798 0.24148612\n",
      "799 0.24137042\n",
      "800 0.24125487\n",
      "801 0.24113944\n",
      "802 0.24102415\n",
      "803 0.24090898\n",
      "804 0.24079403\n",
      "805 0.24067926\n",
      "806 0.24056464\n",
      "807 0.24045014\n",
      "808 0.24033567\n",
      "809 0.24022137\n",
      "810 0.24010713\n",
      "811 0.23999299\n",
      "812 0.23987895\n",
      "813 0.23976506\n",
      "814 0.23965135\n",
      "815 0.23953773\n",
      "816 0.23942424\n",
      "817 0.2393109\n",
      "818 0.23919766\n",
      "819 0.23908448\n",
      "820 0.23897144\n",
      "821 0.23885849\n",
      "822 0.23874567\n",
      "823 0.23863292\n",
      "824 0.23852023\n",
      "825 0.23840766\n",
      "826 0.23829517\n",
      "827 0.23818289\n",
      "828 0.23807067\n",
      "829 0.23795849\n",
      "830 0.23784642\n",
      "831 0.23773447\n",
      "832 0.23762262\n",
      "833 0.23751089\n",
      "834 0.23739924\n",
      "835 0.23728767\n",
      "836 0.2371761\n",
      "837 0.2370646\n",
      "838 0.23695323\n",
      "839 0.236842\n",
      "840 0.23673083\n",
      "841 0.23661979\n",
      "842 0.23650876\n",
      "843 0.23639783\n",
      "844 0.23628697\n",
      "845 0.23617621\n",
      "846 0.23606548\n",
      "847 0.23595494\n",
      "848 0.2358445\n",
      "849 0.23573416\n",
      "850 0.235624\n",
      "851 0.23551396\n",
      "852 0.23540397\n",
      "853 0.2352941\n",
      "854 0.2351843\n",
      "855 0.23507464\n",
      "856 0.23496513\n",
      "857 0.23485577\n",
      "858 0.23474656\n",
      "859 0.23463753\n",
      "860 0.23452865\n",
      "861 0.23441985\n",
      "862 0.2343112\n",
      "863 0.23420267\n",
      "864 0.23409422\n",
      "865 0.23398583\n",
      "866 0.23387747\n",
      "867 0.23376918\n",
      "868 0.233661\n",
      "869 0.23355284\n",
      "870 0.23344485\n",
      "871 0.23333701\n",
      "872 0.2332293\n",
      "873 0.23312166\n",
      "874 0.23301409\n",
      "875 0.23290655\n",
      "876 0.23279908\n",
      "877 0.23269169\n",
      "878 0.23258442\n",
      "879 0.23247723\n",
      "880 0.23237018\n",
      "881 0.2322633\n",
      "882 0.23215654\n",
      "883 0.23204993\n",
      "884 0.2319434\n",
      "885 0.231837\n",
      "886 0.23173071\n",
      "887 0.23162456\n",
      "888 0.23151845\n",
      "889 0.23141243\n",
      "890 0.2313065\n",
      "891 0.23120078\n",
      "892 0.23109517\n",
      "893 0.23098963\n",
      "894 0.23088424\n",
      "895 0.2307789\n",
      "896 0.23067366\n",
      "897 0.23056854\n",
      "898 0.23046364\n",
      "899 0.23035882\n",
      "900 0.2302541\n",
      "901 0.23014942\n",
      "902 0.2300448\n",
      "903 0.22994034\n",
      "904 0.22983594\n",
      "905 0.22973162\n",
      "906 0.22962742\n",
      "907 0.22952335\n",
      "908 0.22941932\n",
      "909 0.22931537\n",
      "910 0.22921142\n",
      "911 0.22910754\n",
      "912 0.2290038\n",
      "913 0.22890015\n",
      "914 0.22879654\n",
      "915 0.22869304\n",
      "916 0.22858956\n",
      "917 0.22848617\n",
      "918 0.22838289\n",
      "919 0.2282797\n",
      "920 0.22817656\n",
      "921 0.22807352\n",
      "922 0.22797056\n",
      "923 0.22786765\n",
      "924 0.22776477\n",
      "925 0.22766198\n",
      "926 0.22755921\n",
      "927 0.22745655\n",
      "928 0.22735408\n",
      "929 0.22725165\n",
      "930 0.2271493\n",
      "931 0.22704701\n",
      "932 0.22694485\n",
      "933 0.22684272\n",
      "934 0.22674072\n",
      "935 0.2266389\n",
      "936 0.22653708\n",
      "937 0.22643532\n",
      "938 0.22633365\n",
      "939 0.22623217\n",
      "940 0.22613072\n",
      "941 0.22602937\n",
      "942 0.22592808\n",
      "943 0.22582692\n",
      "944 0.22572581\n",
      "945 0.22562486\n",
      "946 0.22552401\n",
      "947 0.22542326\n",
      "948 0.22532262\n",
      "949 0.22522202\n",
      "950 0.22512148\n",
      "951 0.22502108\n",
      "952 0.2249207\n",
      "953 0.22482044\n",
      "954 0.22472025\n",
      "955 0.22462016\n",
      "956 0.22452018\n",
      "957 0.22442028\n",
      "958 0.22432046\n",
      "959 0.22422077\n",
      "960 0.2241212\n",
      "961 0.22402179\n",
      "962 0.22392239\n",
      "963 0.22382316\n",
      "964 0.22372404\n",
      "965 0.22362496\n",
      "966 0.223526\n",
      "967 0.22342724\n",
      "968 0.22332858\n",
      "969 0.22323\n",
      "970 0.22313161\n",
      "971 0.22303325\n",
      "972 0.22293507\n",
      "973 0.22283691\n",
      "974 0.22273894\n",
      "975 0.22264102\n",
      "976 0.22254317\n",
      "977 0.22244538\n",
      "978 0.22234766\n",
      "979 0.22225003\n",
      "980 0.22215246\n",
      "981 0.22205487\n",
      "982 0.22195745\n",
      "983 0.2218601\n",
      "984 0.22176291\n",
      "985 0.22166584\n",
      "986 0.22156878\n",
      "987 0.2214718\n",
      "988 0.22137494\n",
      "989 0.22127806\n",
      "990 0.22118127\n",
      "991 0.22108461\n",
      "992 0.22098811\n",
      "993 0.22089165\n",
      "994 0.22079535\n",
      "995 0.22069916\n",
      "996 0.22060312\n",
      "997 0.22050725\n",
      "998 0.22041146\n",
      "999 0.22031578\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    sess.run(train,{x:x_train})\n",
    "    print(i,sess.run(cost, {x:x_train}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[0].reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(hx,{x:x_test[[0]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(hx,{x:x_test[[0]]}).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 \n",
    "aa = sess.run(hx,{x:x_test[[0]]})\n",
    "h = aa.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(h==bb).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
